{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#04B404\"><h1 align=\"center\">PySpark</h1></font>\n",
    "<font color=\"#6E6E6E\"><h2 align=\"center\">HHAR dataset</h2></font>\n",
    "<br>\n",
    "<span>In this notebook we present a basical treatment of the dataset 'Human Activity Recognition'\n",
    "(HHAR https://archive.ics.uci.edu/ml/datasets/Heterogeneity+Activity+Recognition+Data+Set) which contains data cof people's physical movements collected through their phones and watches sensors (gyroscopes and accelerometers). More specifically we will treat 4 csv's files: Phones_accelerometer.csv, Phones_gyroscope.csv,\n",
    "Watch_accelerometer.csv y Watch_gyroscope.csv. Its format is, for all of them, the next (columns):\n",
    "    \n",
    "- Index: record id.\n",
    "- Arrival_Time.\n",
    "- Creation_Time.\n",
    "- X,y,z: x, y and z axis' values of meditions.\n",
    "- User: user identifier from 'a' to 'i'.\n",
    "- Model: phone/watch model.\n",
    "- Device: model device which takes the measure.\n",
    "- Gt: activity user was realizing during the measurement. Posible values are: bike sit, stand, walk, stairsup, stairsdown and null.\n",
    "\n",
    "The goal is to process these datasets to obtain a dataset with next info (not the same format is required):\n",
    "User,Model,gt,mean(x,y,z),stdev(x,y,z),max(x,y,z),min(x,y,z)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark libraries:\n",
    "from pyspark import SparkContext   \n",
    "from pyspark import SparkConf\n",
    "from statistics import mean, stdev \n",
    "import time as t                   # in order to measure execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ((\"sc\" in globals()) or (\"sc\" in locals())):\n",
    "    import pyspark\n",
    "    sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input  -> CSV file\n",
    "Output -> RDD con formato User | Model | Gt | Index | Arrival_Time | Creation_Time | x | y | z | Device\n",
    "\n",
    "'''\n",
    "\n",
    "def createRDD(file):\n",
    "    \n",
    "    RDD = sc.textFile(file) \\\n",
    "            .map(lambda el: el.split(',')) \\\n",
    "            .map(lambda el: (el[6], el[7], el[9], int(el[0]), int(el[1]), float(el[2]), \\\n",
    "                             float(el[3]), float(el[4]), float(el[5]), el[8]) ) \n",
    "            \n",
    "    return RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Función a la cual se le pasa un RDD y una variable tipo string x,y ó z y retorna otro RDD con (clave 3 campos), \n",
    "media(col), std(col), max(col), min(col). Se usan las funciones mean, std de la librería statistics.\n",
    "\n",
    "Input: rdd + string variable to select\n",
    "Output: rdd with format ((key), mean, std, max, min)\n",
    "'''\n",
    "\n",
    "def calc_estad(rdd, var):\n",
    "    if var == 'x':\n",
    "        alt = rdd.map(lambda el: ( (el[0], el[1], el[2]) , el[6]) )\n",
    "    elif var == 'y':\n",
    "        alt = rdd.map(lambda el: ( (el[0], el[1], el[2]) , el[7]) )\n",
    "    else:\n",
    "        alt = rdd.map(lambda el: ( (el[0], el[1], el[2]) , el[8]) )\n",
    "        \n",
    "    rdd_est = alt.groupByKey() \\\n",
    "                 .map(lambda el: (el[0], list(el[1]) ) ) \\\n",
    "                 .map(lambda el: (el[0], (mean(el[1]), stdev(el[1]), max(el[1]), min(el[1])) ) ) \n",
    "            \n",
    "            \n",
    "    return rdd_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = createRDD(\"../data/small_data/Phones_accelerometer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join on three axis x, y, z:\n",
    "rddPhAc = calc_estad(aux1, 'x').join(calc_estad(aux1, 'y')).join(calc_estad(aux1, 'z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se repite el tratamiento para el fichero de Phones_gyroscope.csv:\n",
    "aux2 = creaRDD(\"../data/small_data/Phones_gyroscope.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddPhGyr = calc_estad(aux2, 'x').join(calc_estad(aux2, 'y')).join(calc_estad(aux2, 'z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining both phone gyroscopes RDDs:\n",
    "rddPhones = rddPhAc.join(rddPhGyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same treatment for watchers files:\n",
    "aux3 = creaRDD(\"../data/small_data/Watch_accelerometer.csv\")\n",
    "rddWatAc = calc_estad(aux3, 'x').join(calc_estad(aux3, 'y')).join(calc_estad(aux3, 'z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch_gyroscope.csv\n",
    "aux4 = creaRDD(\"../data/small_data/Watch_gyroscope.csv\")\n",
    "rddWatGyr = calc_estad(aux4, 'x').join(calc_estad(aux4, 'y')).join(calc_estad(aux4, 'z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join:\n",
    "rddWatches = rddWatAc.join(rddWatGyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union of both watches and phones RDDs\n",
    "_rdd = rddPhones.union(rddWatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('a', 'nexus4', 'stand'), ((((-6.02649995057, 0.18456097501476634, -5.5202026, -7.0448303), (0.9334959509016, 0.24044618153708053, 1.9472808999999998, -0.84251404)), (8.01364601312, 0.17600865886717026, 8.638794, 7.149872)), (((0.0015888519490950001, 0.04277706596172393, 0.6321869000000001, -0.16569519), (0.001009460465647, 0.028614446745451536, 0.34971620000000003, -0.15550232)), (0.000442184429349, 0.04594334128107021, 0.44873047, -0.6001586999999999))))\n"
     ]
    }
   ],
   "source": [
    "print(_rdd.collect()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark (Py3)",
   "language": "",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
