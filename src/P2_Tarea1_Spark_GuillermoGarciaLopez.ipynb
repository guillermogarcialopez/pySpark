{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ECOSISTEMA SPARK</h1>\n",
    "<h1>Práctica 2: SparkSQL</h1>\n",
    "<h1>TAREA 1</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Autor: Guillermo García López</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "init_time = t.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comando para habilitar scrolling horizontal en celdas\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea sparksession para utilidades SparkSQL\n",
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL - Practica 2\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea SparkContext() para utilidades sobre RDD's\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos RDD para cada fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Función para crear un RDD a partir del fichero .csv original, con el formato de la utilidad \"Row\" de SparkSQL \n",
    "en base al esquema inferido del fichero:\n",
    "[0] -> Index           (int)\n",
    "[1] -> Arrival_Time    (int)\n",
    "[2] -> Creation_Time   (int)\n",
    "[3] -> x               (float)\n",
    "[4] -> y               (float)\n",
    "[5] -> z               (float)\n",
    "[6] -> User            (string)\n",
    "[7] -> Model           (string)\n",
    "[8] -> Device          (string)\n",
    "[9] -> Gt              (string)\n",
    "\n",
    "Input: nombre de fichero a importar.\n",
    "Output: RDD con el esquema de campos en formato \"Row\"\n",
    "'''\n",
    "def create_RDD(file):\n",
    "    rdd = sc.textFile(file) \\\n",
    "            .map(lambda el: el.split(',')) \\\n",
    "            .map(lambda el: Row( user=str(el[6]), model=str(el[7]), gt=str(el[9]), x=float(el[3]), \\\n",
    "                                 y=float(el[4]), z=float(el[5]) ) )\n",
    "            \n",
    "            #.map(lambda el: Row(index=int(el[0]), arrTime=int(el[1]), crTime=int(el[2]), x=float(el[3]), \\\n",
    "            #                     y=float(el[4]), z=float(el[5]), user=str(el[6]), model=str(el[7]), \\\n",
    "            #                     device=str(el[8]), gt=str(el[9])))\n",
    "            \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Función para crear un dataframe y registrarlo como tabla a partir de un RDD. Los nombres de las tablas \n",
    "serán los siguientes:\n",
    "Phones_accelerometer.csv -> phonesAcc\n",
    "Phones_gyroscope.csv     -> phonesGyr\n",
    "Watch_accelerometer.csv  -> watchesAcc\n",
    "Watch_gyroscope.csv      -> watchesGyr\n",
    "\n",
    "Input: RDD\n",
    "Output: none\n",
    "'''\n",
    "def create_reg_df(rdd):\n",
    "    df = spark.createDataFrame(rdd)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean los RDD's para cada fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phAccRDD  = create_RDD('./large_data/datos_sensores/activity_recognition_exp/Phones_accelerometer.csv')\n",
    "#phGyrRDD  = create_RDD('./large_data/datos_sensores/activity_recognition_exp/Phones_gyroscope.csv')\n",
    "#watAccRDD = create_RDD('./large_data/datos_sensores/activity_recognition_exp/Watch_accelerometer.csv')\n",
    "#watGyrRDD = create_RDD('./large_data/datos_sensores/activity_recognition_exp/Watch_gyroscope.csv')\n",
    "phAccRDD  = create_RDD('./small_data/Phones_accelerometer.csv')\n",
    "phGyrRDD  = create_RDD('./small_data/Phones_gyroscope.csv')\n",
    "watAccRDD = create_RDD('./small_data/Watch_accelerometer.csv')\n",
    "watGyrRDD = create_RDD('./small_data/Watch_gyroscope.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los RDD's se crean los dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPhAcc  = spark.createDataFrame(phAccRDD)\n",
    "dfPhGyr  = spark.createDataFrame(phGyrRDD)\n",
    "dfWatAcc = spark.createDataFrame(watAccRDD)\n",
    "dfWatGyr = spark.createDataFrame(watGyrRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfPhAcc  = create_reg_df(phAccRDD)\n",
    "#dfPhGyr  = create_reg_df(phGyrRDD)\n",
    "#dfWatAcc = create_reg_df(watAccRDD)\n",
    "#dfWatGyr = create_reg_df(watGyrRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonesStats = dfPhAcc.join(dfPhGyr, ['user', 'model', 'gt', 'x', 'y', 'z']  ,'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchesStats = dfWatAcc.join(dfWatGyr, ['user', 'model', 'gt', 'x', 'y', 'z']  ,'full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se unen los dataframes mediante 'union', registrando una tabla del dataframe resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats = phonesStats.unionAll(watchesStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats.createOrReplaceTempView('statsTable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se ejecuta la query que retorna los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT user, model ,gt ,mean(x), mean(y), mean(z) \\\n",
    "                ,std(x), std(y), std(z), max(x), max(y), max(z), min(x) \\\n",
    "                ,min(y), min(z) \\\n",
    "         FROM statsTable \\\n",
    "         GROUP BY user, model, gt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = spark.sql(query)\n",
    "#result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.868576765060425\n"
     ]
    }
   ],
   "source": [
    "end_time = t.time()\n",
    "def foo():\n",
    "    interval_time = end_time - init_time\n",
    "    print(interval_time)\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+-------------------+-------------------+-------------------+-----------------+-------------------+-------------------+------------------+------------------+------------+-----------+-----------+-------------------+\n",
      "|user| model|   gt|             avg(x)|             avg(y)|             avg(z)|   stddev_samp(x)|     stddev_samp(y)|     stddev_samp(z)|            max(x)|            max(y)|      max(z)|     min(x)|     min(y)|             min(z)|\n",
      "+----+------+-----+-------------------+-------------------+-------------------+-----------------+-------------------+-------------------+------------------+------------------+------------+-----------+-----------+-------------------+\n",
      "|   a|  gear| null| -4.625535971408151|-1.7571181213697233|-0.5569131464861713|4.644796091579758| 1.7196641004044204|0.48540930263564325|         0.0561927|      -0.018109497|-0.055127434| -9.3583355| -3.5942953|         -1.1420342|\n",
      "|   a|nexus4|stand|-3.0124555493104537|0.46725270568362365|  4.007044098774675|3.017095178600381|0.49669783961690506|  4.008766103819178|0.6321869000000001|1.9472808999999998|    8.638794| -7.0448303|-0.84251404|-0.6001586999999999|\n",
      "|   a|  gear|stand|-4.6402519535531175|-1.5871617087679704|-0.5695504670902554|4.665656176741632| 1.7252833855066434| 0.6629781369471197|        0.81039995|        0.35446674|   1.1475562| -12.600683|  -11.08276|         -2.2625206|\n",
      "|   a|  gear|  sit|-3.7846925777537717| -2.780411185818033| 1.2819700018548401|3.816281036670717| 2.7507285531522303| 1.3817390257376976|        0.39867523|        0.39920786|    3.555988|-10.8229885| -6.9168487|         -3.6709096|\n",
      "+----+------+-----+-------------------+-------------------+-------------------+-----------------+-------------------+-------------------+------------------+------------------+------------+-----------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
